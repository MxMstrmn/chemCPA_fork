{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the load data, model initialization and manual training functions\n",
    "test the codes on some randomly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/zkm/Desktop/chemCPA_fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "from chemCPA.data import load_dataset_splits\n",
    "from chemCPA.model import ComPert\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the datasets\n",
    "7 subdatasets in total: training; training_control; training_treated; test; test_control; test_treated; ood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "\n",
    "# a collection of datasets generated by some random adata\n",
    "# the knockout embeddings will be generated randomly\n",
    "datasets = load_dataset_splits(\n",
    "                                \"Comb.h5ad\",\n",
    "                                drug_key=None,\n",
    "                                dose_key=None,\n",
    "                                drugs_embeddings=None,\n",
    "                                knockout_key=\"treatment\",\n",
    "                                knockouts_embeddings=None,\n",
    "                                covariate_keys=[\"cell_line\"],\n",
    "                                smiles_key=None,\n",
    "                                pert_category=\"pert_category\",\n",
    "                                split_key=\"split\",\n",
    "                                degs_key='rank_genes_groups_cov'\n",
    "                                )\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55050\n",
      "3724\n",
      "51326\n",
      "10485\n",
      "725\n",
      "9760\n",
      "1260\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets['training']))\n",
    "print(len(datasets['training_control']))\n",
    "print(len(datasets['training_treated']))\n",
    "print(len(datasets['test']))\n",
    "print(len(datasets['test_control']))\n",
    "print(len(datasets['test_treated']))\n",
    "print(len(datasets['ood']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "# the knockouts embeddings are initialized as random \n",
    "model = ComPert(\n",
    "    datasets[\"training\"].num_genes,\n",
    "    datasets[\"training\"].num_drugs,\n",
    "    datasets[\"training\"].num_knockouts,\n",
    "    datasets[\"training\"].num_covariates,\n",
    "    device=device,\n",
    "    drug_embedding_dimension=None,\n",
    "    knockout_embedding_dimension=256,\n",
    "    knockout_effect_type=\"sigm\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train functions and collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, epoch):\n",
    "    batch_ct = epoch * len(loader)\n",
    "    cumu_loss = {\n",
    "        \"loss_reconstruction\":0,\n",
    "        \"loss_adv_drugs\":0,\n",
    "        \"loss_adv_knockouts\":0,\n",
    "        \"loss_adv_covariates\":0,\n",
    "    }\n",
    "    for data in loader:\n",
    "        genes, drugs_idx, dosages, drugs_embeddings, knockouts_idx, knockouts_embeddings, covariates_idx = (\n",
    "                    data[0],\n",
    "                    data[1],\n",
    "                    data[2],\n",
    "                    data[3],\n",
    "                    data[4],\n",
    "                    data[5],\n",
    "                    data[6:]\n",
    "                )\n",
    "        training_stats = model.update(\n",
    "            genes=genes,\n",
    "            drugs_idx=drugs_idx,\n",
    "            dosages=dosages,\n",
    "            drugs_embeddings = drugs_embeddings,\n",
    "            knockouts_idx=knockouts_idx,\n",
    "            knockouts_embeddings = knockouts_embeddings,\n",
    "            covariates_idx=covariates_idx,     \n",
    "                )\n",
    "        batch_ct += 1\n",
    "        wandb.log({\"batch_loss_reconstruction\": training_stats[\"loss_reconstruction\"], \"batch_ct\": batch_ct})\n",
    "        wandb.log({\"batch_loss_adv_drugs\": training_stats[\"loss_adv_drugs\"], \"batch_ct\": batch_ct})\n",
    "        wandb.log({\"batch_loss_adv_knockouts\": training_stats[\"loss_adv_knockouts\"], \"batch_ct\": batch_ct})\n",
    "        wandb.log({\"batch_loss_adv_covariates\": training_stats[\"loss_adv_covariates\"], \"batch_ct\": batch_ct})\n",
    "\n",
    "        cumu_loss = {i: (cumu_loss[i]+training_stats[i]) for i in cumu_loss.keys()}\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    return {i: cumu_loss[i]/len(loader) for i in cumu_loss.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a naive collate function for only one covariate\n",
    "# todo: improve the collate function\n",
    "\n",
    "def custom_collate(batch):\n",
    "    genes, drugs_idx, dosages, drugs_emb, knockouts_idx, knockouts_emb, cov = zip(*batch)\n",
    "    genes = torch.stack(genes, 0).to(device)\n",
    "    drugs_idx = None if drugs_idx[0] is None else [d.to(device) for d in drugs_idx]\n",
    "    dosages = None if dosages[0] is None else [d.to(device) for d in dosages]\n",
    "    drugs_emb = None if drugs_emb[0] is None else [d.to(device) for d in drugs_emb]\n",
    "    knockouts_idx = None if knockouts_idx[0] is None else [d.to(device) for d in knockouts_idx]\n",
    "    knockouts_emb = None if knockouts_emb[0] is None else [d.to(device) for d in knockouts_emb]\n",
    "    cov = None if cov[0] is None else  torch.stack(cov, 0).to(device)\n",
    "    return [genes, drugs_idx, dosages, drugs_emb, knockouts_idx, knockouts_emb, cov]\n",
    "\n",
    "\n",
    "\n",
    "def train(model, datasets):\n",
    "    with wandb.init(project=\"cpa\", config=model.hparams):\n",
    "        datasets.update(\n",
    "            {\n",
    "                \"loader_tr\": torch.utils.data.DataLoader(\n",
    "                    datasets[\"training\"],\n",
    "                    batch_size=model.hparams[\"batch_size\"],\n",
    "                    collate_fn=custom_collate,\n",
    "                    shuffle=True,\n",
    "                    )\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        wandb.define_metric(\"batch_loss_reconstruction\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"batch_loss_adv_drugs\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"batch_loss_adv_knockouts\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"batch_loss_adv_covariates\", step_metric=\"batch_ct\")\n",
    "        \n",
    "        wandb.define_metric(\"epoch_loss_reconstruction\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"epoch_loss_adv_drugs\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"epoch_loss_adv_knockouts\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"epoch_loss_adv_covariates\", step_metric=\"epoch\")\n",
    "        \n",
    "        for epoch in range(100):\n",
    "            avg_stats = train_epoch(model, datasets[\"loader_tr\"], epoch)\n",
    "            wandb.log({\"epoch_loss_reconstruction\": avg_stats[\"loss_reconstruction\"], \"epoch\": epoch})\n",
    "            wandb.log({\"epoch_loss_adv_drugs\": avg_stats[\"loss_adv_drugs\"], \"epoch\": epoch})\n",
    "            wandb.log({\"epoch_loss_adv_knockouts\": avg_stats[\"loss_adv_knockouts\"], \"epoch\": epoch})\n",
    "            wandb.log({\"epoch_loss_adv_covariates\": avg_stats[\"loss_adv_covariates\"], \"epoch\": epoch})\n",
    "            \n",
    "     \n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual run of the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the evaluation codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import evaluate_logfold_r2, evaluate_disentanglement, evaluate_r2, evaluate_r2_sc, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 combinations had '-inf' R2 scores:\n",
      "\t set()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6732103911763064, -13.59968694131729, -88.9191639934421, -784.672868597486]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.eval()\n",
    "#evaluate_logfold_r2(model, datasets['test_treated'], datasets['test_control'])\n",
    "#evaluate_disentanglement(model, datasets['test'])\n",
    "#evaluate_r2(model, datasets[\"test_treated\"], datasets['test_control'].genes)\n",
    "#evaluate_r2_sc(model, datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model,\n",
    "    datasets,\n",
    "    {},\n",
    "    run_disentangle=True,\n",
    "    run_r2=False,\n",
    "    run_r2_sc=False,\n",
    "    run_logfold=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheet5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

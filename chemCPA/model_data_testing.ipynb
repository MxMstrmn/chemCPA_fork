{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the load data, model initialization and manual training functions\n",
    "test the codes on some randomly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkemingzhang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "from chemCPA.data import load_dataset_splits\n",
    "from chemCPA.model import ComPert\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the datasets\n",
    "7 subdatasets in total: training; training_control; training_treated; test; test_control; test_treated; ood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "\n",
    "# a collection of datasets generated by some random adata\n",
    "# the knockout embeddings will be generated randomly\n",
    "datasets = load_dataset_splits(\n",
    "                                \"fake.h5ad\",\n",
    "                                drug_key=None,\n",
    "                                dose_key=None,\n",
    "                                drugs_embeddings=None,\n",
    "                                knockout_key=\"guide_merged\",\n",
    "                                knockouts_embeddings=None,\n",
    "                                covariate_keys=[\"cell_type\"],\n",
    "                                smiles_key=None,\n",
    "                                pert_category=\"pert_category\",\n",
    "                                split_key=\"split\"\n",
    "                                )\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "# the knockouts embeddings are initialized as random \n",
    "model = ComPert(\n",
    "    datasets[\"training\"].num_genes,\n",
    "    datasets[\"training\"].num_drugs,\n",
    "    datasets[\"training\"].num_knockouts,\n",
    "    datasets[\"training\"].num_covariates,\n",
    "    device=device,\n",
    "    drug_embedding_dimension=None,\n",
    "    knockout_embedding_dimension=256,\n",
    "    knockout_effect_type=\"sigm\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train functions and collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, epoch):\n",
    "    batch_ct = epoch * len(loader)\n",
    "    cumu_loss = {\n",
    "        \"loss_reconstruction\":0,\n",
    "        \"loss_adv_drugs\":0,\n",
    "        \"loss_adv_knockouts\":0,\n",
    "        \"loss_adv_covariates\":0,\n",
    "    }\n",
    "    for data in loader:\n",
    "        genes, drugs_idx, dosages, drugs_embeddings, knockouts_idx, knockouts_embeddings, covariates_idx = (\n",
    "                    data[0],\n",
    "                    data[1],\n",
    "                    data[2],\n",
    "                    data[3],\n",
    "                    data[4],\n",
    "                    data[5],\n",
    "                    data[6:]\n",
    "                )\n",
    "        training_stats = model.update(\n",
    "            genes=genes,\n",
    "            drugs_idx=drugs_idx,\n",
    "            dosages=dosages,\n",
    "            drugs_embeddings = drugs_embeddings,\n",
    "            knockouts_idx=knockouts_idx,\n",
    "            knockouts_embeddings = knockouts_embeddings,\n",
    "            covariates_idx=covariates_idx,     \n",
    "                )\n",
    "        batch_ct += 1\n",
    "        wandb.log({\"batch_loss_reconstruction\": training_stats[\"loss_reconstruction\"], \"batch_ct\": batch_ct})\n",
    "        wandb.log({\"batch_loss_adv_drugs\": training_stats[\"loss_adv_drugs\"], \"batch_ct\": batch_ct})\n",
    "        wandb.log({\"batch_loss_adv_knockouts\": training_stats[\"loss_adv_knockouts\"], \"batch_ct\": batch_ct})\n",
    "        wandb.log({\"batch_loss_adv_covariates\": training_stats[\"loss_adv_covariates\"], \"batch_ct\": batch_ct})\n",
    "\n",
    "        cumu_loss = {i: (cumu_loss[i]+training_stats[i]) for i in cumu_loss.keys()}\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    return {i: cumu_loss[i]/len(loader) for i in cumu_loss.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a naive collate function for only one covariate\n",
    "# todo: improve the collate function\n",
    "\n",
    "def custom_collate(batch):\n",
    "    genes, drugs_idx, dosages, drugs_emb, knockouts_idx, knockouts_emb, cov = zip(*batch)\n",
    "    genes = torch.stack(genes, 0).to(device)\n",
    "    drugs_idx = None if drugs_idx[0] is None else [d.to(device) for d in drugs_idx]\n",
    "    dosages = None if dosages[0] is None else [d.to(device) for d in dosages]\n",
    "    drugs_emb = None if drugs_emb[0] is None else [d.to(device) for d in drugs_emb]\n",
    "    knockouts_idx = None if knockouts_idx[0] is None else [d.to(device) for d in knockouts_idx]\n",
    "    knockouts_emb = None if knockouts_emb[0] is None else [d.to(device) for d in knockouts_emb]\n",
    "    cov = None if cov[0] is None else  torch.stack(cov, 0).to(device)\n",
    "    return [genes, drugs_idx, dosages, drugs_emb, knockouts_idx, knockouts_emb, cov]\n",
    "\n",
    "\n",
    "\n",
    "def train(model, datasets):\n",
    "    with wandb.init(project=\"cpa\", config=model.hparams):\n",
    "\n",
    "        datasets.update(\n",
    "            {\n",
    "                \"loader_tr\": torch.utils.data.DataLoader(\n",
    "                    datasets[\"training\"],\n",
    "                    batch_size=model.hparams[\"batch_size\"],\n",
    "                    collate_fn=custom_collate,\n",
    "                    shuffle=True,\n",
    "                    )\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        wandb.define_metric(\"batch_loss_reconstruction\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"batch_loss_adv_drugs\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"batch_loss_adv_knockouts\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"batch_loss_adv_covariates\", step_metric=\"batch_ct\")\n",
    "        \n",
    "        wandb.define_metric(\"epoch_loss_reconstruction\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"epoch_loss_adv_drugs\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"epoch_loss_adv_knockouts\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"epoch_loss_adv_covariates\", step_metric=\"epoch\")\n",
    "        \n",
    "        for epoch in range(1):\n",
    "            avg_stats = train_epoch(model, datasets[\"loader_tr\"], epoch)\n",
    "            wandb.log({\"epoch_loss_reconstruction\": avg_stats[\"loss_reconstruction\"], \"epoch\": epoch})\n",
    "            wandb.log({\"epoch_loss_adv_drugs\": avg_stats[\"loss_adv_drugs\"], \"epoch\": epoch})\n",
    "            wandb.log({\"epoch_loss_adv_knockouts\": avg_stats[\"loss_adv_knockouts\"], \"epoch\": epoch})\n",
    "            wandb.log({\"epoch_loss_adv_covariates\": avg_stats[\"loss_adv_covariates\"], \"epoch\": epoch})\n",
    "            \n",
    "     \n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual run of the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/zkm/Desktop/chemCPA_fork/chemCPA/wandb/run-20240128_104316-xv4g9v4t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kemingzhang/cpa/runs/xv4g9v4t' target=\"_blank\">peach-armadillo-40</a></strong> to <a href='https://wandb.ai/kemingzhang/cpa' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kemingzhang/cpa' target=\"_blank\">https://wandb.ai/kemingzhang/cpa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kemingzhang/cpa/runs/xv4g9v4t' target=\"_blank\">https://wandb.ai/kemingzhang/cpa/runs/xv4g9v4t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c773ee4c7542feb154fcffd477a845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_ct</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch_loss_adv_covariates</td><td>▇▇▅▆▁█▃▆▇▆▄▄▆▄▅█▇▅▆▅▆▅▆▂▄▅▃▅▃▂▆▃▅▂▃▁▁▅▁█</td></tr><tr><td>batch_loss_adv_drugs</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss_adv_knockouts</td><td>▄▄▅▆▄▆▇▅▃▅▅▁▃▂▃▅▄▆▄▄▂▇▆▄█▆▇▇▄▅▆▃▃▅▄█▄▅▄▂</td></tr><tr><td>batch_loss_reconstruction</td><td>█▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▂▁▂▂▁▂▂</td></tr><tr><td>epoch</td><td>▁▁▁▁</td></tr><tr><td>epoch_loss_adv_covariates</td><td>▁</td></tr><tr><td>epoch_loss_adv_drugs</td><td>▁</td></tr><tr><td>epoch_loss_adv_knockouts</td><td>▁</td></tr><tr><td>epoch_loss_reconstruction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_ct</td><td>118</td></tr><tr><td>batch_loss_adv_covariates</td><td>2.12337</td></tr><tr><td>batch_loss_adv_drugs</td><td>0.0</td></tr><tr><td>batch_loss_adv_knockouts</td><td>6.5844</td></tr><tr><td>batch_loss_reconstruction</td><td>-1.31836</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>epoch_loss_adv_covariates</td><td>2.08669</td></tr><tr><td>epoch_loss_adv_drugs</td><td>0.0</td></tr><tr><td>epoch_loss_adv_knockouts</td><td>6.80522</td></tr><tr><td>epoch_loss_reconstruction</td><td>-1.12191</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-armadillo-40</strong> at: <a href='https://wandb.ai/kemingzhang/cpa/runs/xv4g9v4t' target=\"_blank\">https://wandb.ai/kemingzhang/cpa/runs/xv4g9v4t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_104316-xv4g9v4t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ComPert(\n",
       "  (encoder): MLP(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=2000, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (10): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): MLP(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (10): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=512, out_features=4000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (adversary_knockouts): MLP(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=128, out_features=47, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (knockout_embedding_encoder): MLP(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss_adversary_knockout): CELoss()\n",
       "  (knockout_effects): GeneralizedSigmoid()\n",
       "  (loss_autoencoder): GaussianNLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the evaluation codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## currently, the fake data do not suppert degs, so that the r2 scores based on degs cannot be tested\n",
    "## todo: get a complete anndata set and test the evaluation codes\n",
    "\n",
    "\n",
    "\n",
    "genes = datasets['test'].genes\n",
    "knockouts_idx = datasets['test'].knockouts_idx\n",
    "knockouts_embeddings = [datasets['test'].knockouts_embeddings(idx) for idx in knockouts_idx]\n",
    "covariate_idx = datasets['test'].covariates_idx\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred = model.predict(genes,\n",
    "                        drugs_idx=None,\n",
    "                        dosages=None,\n",
    "                        drugs_embeddings=None,\n",
    "                        knockouts_idx=knockouts_idx,\n",
    "                        knockouts_embeddings=knockouts_embeddings,\n",
    "                        covariates_idx=covariate_idx\n",
    "                        )\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import compute_r2\n",
    "pred = pred[:, 0:2000].mean(dim=0)\n",
    "genes = genes.mean(dim=0)\n",
    "compute_r2(genes.to(device), pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheet5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

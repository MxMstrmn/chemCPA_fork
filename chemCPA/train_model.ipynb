{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training chemCPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has two dependencies:\n",
    "\n",
    "sciplex3\n",
    "wget \n",
    "rdkit embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a self-contained way to train the chemCPA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmartin-biroscak\u001b[0m (\u001b[33mbiroscak\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "from chemCPA.data import DataModule\n",
    "from chemCPA.model import ComPert\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import yaml\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../experiments/hydra_config/dataset/sciplex_lincs.yaml') as file:\n",
    "    config_dataset = yaml.safe_load(file)\n",
    "with open('../experiments/hydra_config/model/cpa.yaml') as file:\n",
    "    config_model = yaml.safe_load(file)\n",
    "with open('../experiments/hydra_config/test/test.yaml') as file:\n",
    "    config_test = yaml.safe_load(file)\n",
    "with open('../experiments/hydra_config/train/train.yaml') as file:\n",
    "    config_train = yaml.safe_load(file)\n",
    "\n",
    "#seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the dataset module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(config_model['hparams']['batch_size'],\n",
    "                config_train['full_eval_during_train'],\n",
    "                **config_dataset['data_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248258\n",
      "9105\n",
      "239153\n",
      "52966\n",
      "1963\n",
      "51003\n",
      "53416\n"
     ]
    }
   ],
   "source": [
    "print(len(dm.datasets['training']))\n",
    "print(len(dm.datasets['training_control']))\n",
    "print(len(dm.datasets['training_treated']))\n",
    "print(len(dm.datasets['test']))\n",
    "print(len(dm.datasets['test_control']))\n",
    "print(len(dm.datasets['test_treated']))\n",
    "print(len(dm.datasets['ood']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 17]\n",
      "188\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dm.datasets['training'].num_covariates)\n",
    "print(dm.datasets['training'].num_drugs)\n",
    "print(dm.datasets['training'].num_knockouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([tensor([0.]), tensor([10000.]), tensor([1000.]), ...,\n",
       "       tensor([1000.]), tensor([1000.]), tensor([100.])], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.datasets[\"ood\"].dosages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "# the knockouts embeddings are initialized as random \n",
    "model = ComPert(\n",
    "    dm.datasets['training'].num_genes,\n",
    "    dm.datasets['training'].num_drugs,\n",
    "    dm.datasets['training'].num_knockouts,\n",
    "    dm.datasets['training'].num_covariates,\n",
    "    config_model['hparams'],\n",
    "    config_train,\n",
    "    config_test,\n",
    "    **config_model['additional_params'],\n",
    "    drug_embedding_dimension=dm.datasets['training'].drug_embedding_dimension,\n",
    "    knockout_embedding_dimension=dm.datasets['training'].knockout_embedding_dimension,\n",
    "    train_adversarial=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping('average_r2_score', \n",
    "                                    patience=model.hparams.training_params['patience'], \n",
    "                                    mode='max')\n",
    "wandb_logger = WandbLogger(\n",
    "        project = config_model['model_type'] + \"_\" + config_dataset['dataset_type'],\n",
    "        save_dir = config_model['save_dir']     \n",
    "    )\n",
    "inference_mode = ((not config_train['run_eval_disentangle']) and (not config_test['run_eval_disentangle']))\n",
    "trainer = L.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    max_epochs=config_train['num_epochs'],\n",
    "    max_time=config_train['max_time'],\n",
    "    check_val_every_n_epoch= config_train['checkpoint_freq'],\n",
    "    default_root_dir=config_model['save_dir'],\n",
    "    profiler=\"advanced\",\n",
    "    callbacks=[early_stop_callback],\n",
    "    inference_mode=inference_mode,\n",
    "    num_sanity_val_steps=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                   | Type            | Params\n",
      "-----------------------------------------------------------\n",
      "0 | loss_autoencoder       | GaussianNLLLoss | 0     \n",
      "1 | encoder                | MLP             | 1.4 M \n",
      "2 | decoder                | MLP             | 1.9 M \n",
      "3 | adversary_drugs        | MLP             | 74.6 K\n",
      "4 | drug_embedding_encoder | MLP             | 693 K \n",
      "5 | loss_adversary_drugs   | CELoss          | 0     \n",
      "6 | dosers                 | ModuleList      | 36.3 K\n",
      "-----------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.095    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: |                                                                                                        | 0/? [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reload the model from check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the model from check point\n",
    "#model = ComPert.load_from_checkpoint('train_data/CPA/3gm2eppz/checkpoints/epoch=14-step=10560.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drawing the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "from chemCPA.train import evaluate_logfold_r2, evaluate_r2, evaluate_r2_sc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the logfold r2\n",
    "def draw_logfold_r2(autoencoder, ds_treated, ds_ctrl):\n",
    "    logfold_score, signs_score = evaluate_logfold_r2(autoencoder, ds_treated, ds_ctrl, return_mean=False)\n",
    "    df = pd.DataFrame(\n",
    "        data = {'logfold_score': logfold_score, 'signs_score': signs_score}\n",
    "    )\n",
    "    df = pd.melt(df, value_vars=['logfold_score', 'signs_score'], var_name='score_type', value_name='score')\n",
    "    p = ggplot(df, aes(x='factor(score_type)', y='score', fill='factor(score_type)')) + geom_boxplot() + scale_y_continuous(limits=(-1,1))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the r2\n",
    "def draw_r2(autoencoder, dataset, genes_control):\n",
    "    mean_score, mean_score_de, var_score, var_score_de = evaluate_r2(autoencoder, dataset, genes_control, return_mean=False)\n",
    "    df = pd.DataFrame(\n",
    "        data = {'mean_score': mean_score, \n",
    "                'mean_score_de': mean_score_de,\n",
    "                'var_score': var_score,\n",
    "                'var_score_de':var_score_de\n",
    "                }\n",
    "    )\n",
    "    df = pd.melt(df, value_vars=['mean_score', 'mean_score_de', 'var_score', 'var_score_de'], \n",
    "                 var_name='score_type', value_name='score')\n",
    "    p = ggplot(df, aes(x='factor(score_type)', y='score', fill='factor(score_type)')) + geom_boxplot()+ scale_y_continuous(limits=(0,1))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the r2 sc\n",
    "def draw_r2_sc(autoencoder, dataset):\n",
    "    mean_score, mean_score_de, var_score, var_score_de = evaluate_r2_sc(autoencoder, dataset, return_mean=False)\n",
    "    df = pd.DataFrame(\n",
    "        data = {'mean_score': mean_score, \n",
    "                'mean_score_de': mean_score_de,\n",
    "                'var_score': var_score,\n",
    "                'var_score_de':var_score_de\n",
    "                }\n",
    "    )\n",
    "    df = pd.melt(df, value_vars=['mean_score', 'mean_score_de', 'var_score', 'var_score_de'], \n",
    "                 var_name='score_type', value_name='score')\n",
    "    p = ggplot(df, aes(x='factor(score_type)', y='score', fill='factor(score_type)')) + geom_boxplot()+ scale_y_continuous(limits=(0,1))\n",
    "    return p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemCPA",
   "language": "python",
   "name": "chemcpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
